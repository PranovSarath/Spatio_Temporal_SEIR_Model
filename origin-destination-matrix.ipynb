{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6679e5ca",
   "metadata": {},
   "source": [
    "# 1. Calculate the Origin-Destination Matrix to model travel across the city grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard and specialised module imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, shape, box\n",
    "import geopandas as gpd\n",
    "from geopy.geocoders import Nominatim, GoogleV3\n",
    "from shapely.ops import unary_union\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432263b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_polyframe_3857_populated = gpd.read_file('London_grids_with_population.shp')\n",
    "london_polyframe_3857_populated                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "west, south, east, north = london_polyframe_3857_populated.unary_union.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4e331",
   "metadata": {},
   "source": [
    "## 1.1. TFL Tube Data 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb25b9",
   "metadata": {},
   "source": [
    "### 1.1.1. Read Input Datasets (Monday to Thursday, Friday, Saturday and Sunday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279fbe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfl_tube_flows_data_MTT = pd.read_excel('Important Data/NBT20MTT_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
    "tfl_tube_flows_data_MTT\n",
    "\n",
    "tfl_tube_flows_data_FRI = pd.read_excel('Important Data/NBT20FRI_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
    "tfl_tube_flows_data_FRI\n",
    "\n",
    "tfl_tube_flows_data_SAT = pd.read_excel('Important Data/NBT20SAT_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
    "tfl_tube_flows_data_SAT\n",
    "\n",
    "tfl_tube_flows_data_SUN = pd.read_excel('Important Data/NBT20SUN_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
    "tfl_tube_flows_data_SUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d89bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfl_tube_flows_data_MTT.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807efebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfl_tube_flows_data_filtered = tfl_tube_flows_data_MTT[['Line', 'Order', 'From Station', 'To Station', 'Total']].copy()\n",
    "tfl_tube_flows_data_filtered.loc[:,'From Station'] = tfl_tube_flows_data_filtered['From Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
    "tfl_tube_flows_data_filtered.loc[:,'To Station'] = tfl_tube_flows_data_filtered['To Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
    "tfl_tube_flows_data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778552e6",
   "metadata": {},
   "source": [
    "### 1.1.2. Generate a dataframe containing the distinct stations in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_station_list = tfl_tube_flows_data_filtered['From Station'].dropna().tolist()\n",
    "to_station_list = tfl_tube_flows_data_filtered['To Station'].dropna().tolist()\n",
    "\n",
    "unique_stations_list = list(set(to_station_list).union(set(from_station_list)))\n",
    "len(unique_stations_list)\n",
    "\n",
    "df_stations = pd.DataFrame({'Station Name': unique_stations_list})\n",
    "df_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590ffbd",
   "metadata": {},
   "source": [
    "### 1.1.3. Figure out the coordinates of the London Tube Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Nominatim geocoder \n",
    "#using GoogleMaps API\n",
    "geolocator = GoogleV3(api_key='AIzaSyAVnb7ljcNMRkV0B40OFW0VTIT6PB-e-hw')\n",
    "geolocator.geocode(\"Waterloo London Underground\").point\n",
    "\n",
    "# Function to get the Point for each station name\n",
    "def fn_get_point_gmaps(station_name):\n",
    "    location = geolocator.geocode(station_name + \" Station, London, UK\").point\n",
    "    if location:\n",
    "        return Point(location.longitude, location.latitude)  # Note: Longitude comes first, then Latitude\n",
    "    else:\n",
    "        location = geolocator.geocode(station_name + \" , London, UK\").point\n",
    "        if location:\n",
    "            return Point(location.longitude, location.latitude)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Apply the function to the 'StationName' column and create a new 'Point' column\n",
    "df_stations['Point'] = df_stations['Station Name'].apply(fn_get_point_gmaps)\n",
    "df_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c058d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = df_stations.rename(columns={'Point':'geometry'})\n",
    "gdf_stations = gpd.GeoDataFrame(df_stations, crs='epsg:4326')\n",
    "gdf_stations.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stations = gdf_stations.to_crs('3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the rest of the map in the background\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "gdf_stations.plot(column='geometry', ax=ax ,figsize=(40,40), alpha=0.5, edgecolor='r', linewidth=10, cmap='magma')\n",
    "london_polyframe_3857_populated.plot(figsize=(40, 40), ax=ax ,alpha=0.5, edgecolor='k',linewidth=3)\n",
    "\n",
    "ctx.add_basemap(ax, zoom=13)\n",
    "#ax.set_xlim(west, east)\n",
    "#ax.set_ylim(south, north)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_buildGriddedTubeDataset(gdf_tube_dataset_input, gdf_stations_london, gdf_population_data):\n",
    "    \n",
    "    gdf_tube_dataset_filtered_input = gdf_tube_dataset_input[['Line', 'Order', 'From Station', 'To Station', 'Total']].copy()\n",
    "    gdf_tube_dataset_filtered_input.loc[:,'From Station'] = gdf_tube_dataset_filtered_input['From Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
    "    gdf_tube_dataset_filtered_input.loc[:,'To Station'] = gdf_tube_dataset_filtered_input['To Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
    "    print(gdf_tube_dataset_filtered_input)\n",
    "    \n",
    "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input.merge(gdf_stations_london, left_on='From Station', right_on='Station Name', how='inner')\n",
    "    gdf_tube_dataset_filtered_input_coords['From Station Coords'] = gdf_tube_dataset_filtered_input_coords['geometry']\n",
    "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.drop(['geometry', 'Station Name'], axis=1)\n",
    "\n",
    "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.merge(gdf_stations_london, left_on='To Station', right_on='Station Name', how='inner')\n",
    "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.rename(columns={'geometry': 'To Station Coords'})\n",
    "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.drop(['Station Name'], axis=1)\n",
    "    print(gdf_tube_dataset_filtered_input_coords)\n",
    "    \n",
    "    gdf_tube_dataset_filtered_input_coords_from = gdf_tube_dataset_filtered_input_coords.copy()\n",
    "    gdf_tube_dataset_filtered_input_coords_from['geometry'] = gdf_tube_dataset_filtered_input_coords_from['From Station Coords']\n",
    "    gdf_tube_dataset_filtered_input_coords_from = gpd.GeoDataFrame(gdf_tube_dataset_filtered_input_coords_from, crs='3857')\n",
    "    gdf_tube_dataset_filtered_input_coords_from\n",
    "\n",
    "\n",
    "    start_join = gpd.sjoin(gdf_tube_dataset_filtered_input_coords_from.to_crs('3857'), gdf_population_data[['geometry', 'grid_index']].to_crs('3857'), how='left', predicate='within')\n",
    "    start_join['From Grid ID'] = start_join['grid_index']\n",
    "    start_join = start_join.drop(['index_right', 'grid_index'], axis=1)\n",
    "\n",
    "    start_join['geometry'] = start_join['To Station Coords']\n",
    "    end_join = gpd.sjoin(start_join.to_crs('3857'), gdf_population_data[['geometry', 'grid_index']].to_crs('3857'), how='left', predicate='within')\n",
    "    end_join['To Grid ID'] = end_join['grid_index']\n",
    "    end_join = end_join.drop(['index_right','grid_index'], axis=1)\n",
    "    print(end_join)\n",
    "    \n",
    "    #Filter out stations that lie outside the London city limits\n",
    "    end_join_filtered = end_join[~end_join['To Grid ID'].isnull() & ~end_join['From Grid ID'].isnull()]\n",
    "    end_join_filtered\n",
    "    \n",
    "    return end_join_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b495fab",
   "metadata": {},
   "source": [
    "### 1.1.3. Calculate the Flow Data for MTT, FRI, SAT and SUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01361db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_tube_flow_MTT = fn_buildGriddedTubeDataset(tfl_tube_flows_data_MTT, gdf_stations, london_polyframe_3857_populated)\n",
    "gdf_tube_flow_MTT\n",
    "\n",
    "gdf_tube_flow_FRI = fn_buildGriddedTubeDataset(tfl_tube_flows_data_FRI, gdf_stations, london_polyframe_3857_populated)\n",
    "gdf_tube_flow_FRI\n",
    "\n",
    "gdf_tube_flow_SAT = fn_buildGriddedTubeDataset(tfl_tube_flows_data_SAT, gdf_stations, london_polyframe_3857_populated)\n",
    "gdf_tube_flow_SAT\n",
    "\n",
    "gdf_tube_flow_SUN = fn_buildGriddedTubeDataset(tfl_tube_flows_data_SUN, gdf_stations, london_polyframe_3857_populated)\n",
    "gdf_tube_flow_SUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53333d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the rest of the map in the background\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "gdf_tube_flow_MTT.plot(figsize=(40, 40), ax=ax, column='geometry', alpha=0.5, edgecolor='r', linewidth=30)\n",
    "london_polyframe_3857_populated.plot('geometry', figsize=(40, 40),alpha=0.5, ax=ax, edgecolor='k',linewidth=3)\n",
    "\n",
    "for idx, row in london_polyframe_3857_populated.iterrows():\n",
    "    label = row['grid_index']  # Replace 'grid_index' with the desired column containing labels or information\n",
    "    centroid_coords = row['geometry'].centroid.coords[0]\n",
    "    ax.annotate(text=label, xy=centroid_coords, horizontalalignment='center', size=30)\n",
    "\n",
    "ctx.add_basemap(ax, zoom=13)\n",
    "ax.set_xlim(west, east)\n",
    "ax.set_ylim(south, north)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c987ee60",
   "metadata": {},
   "source": [
    "## 1.2. Build the Origin-Destination Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generateODMatrix(gdf_flow_dataset, gdf_population_data):\n",
    "    # Get the unique Grid IDs\n",
    "    grid_ids = gdf_population_data['grid_index'].unique()\n",
    "\n",
    "    # Create a weighted graph using NetworkX\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges with total people as edge weights\n",
    "    for index, row in gdf_flow_dataset.iterrows():\n",
    "        from_grid_id = row['From Grid ID']\n",
    "        to_grid_id = row['To Grid ID']\n",
    "        total_people = row['Total']\n",
    "\n",
    "        if G.has_edge(from_grid_id, to_grid_id):\n",
    "            G[from_grid_id][to_grid_id]['weight'] += total_people\n",
    "        else:\n",
    "            G.add_edge(from_grid_id, to_grid_id, weight=total_people)\n",
    "\n",
    "    # Use Floyd-Warshall algorithm to find shortest paths and total flow between all pairs of grids\n",
    "    all_pairs_shortest_paths = dict(nx.floyd_warshall(G, weight='weight'))\n",
    "\n",
    "    # Create a square matrix to store the OD flow\n",
    "    od_matrix = pd.DataFrame(np.zeros((len(grid_ids), len(grid_ids))), index=grid_ids, columns=grid_ids, dtype=float)\n",
    "\n",
    "    # Populate the OD matrix with total flow between all pairs of grids\n",
    "    for from_grid_id, to_grid_data in all_pairs_shortest_paths.items():\n",
    "        for to_grid_id, total_flow in to_grid_data.items():\n",
    "            od_matrix.at[from_grid_id, to_grid_id] = total_flow\n",
    "\n",
    "    # Normalize the OD matrix to values between 0 and 1\n",
    "    #od_matrix_normalized = (od_matrix - od_matrix.min().min()) / (od_matrix.max().max() - od_matrix.min().min())\n",
    "\n",
    "    # Normalize the OD matrix to values between 0 and 1\n",
    "    row_sums = od_matrix.sum(axis=1)\n",
    "    od_matrix_normalized = od_matrix.div(row_sums, axis=0)\n",
    "    # Handle division by zero and set NaN values to 0\n",
    "    od_matrix_normalized = od_matrix_normalized.fillna(0.0)\n",
    "    od_matrix_normalized = round(od_matrix_normalized,5)\n",
    "\n",
    "    # Optionally, you can add human-readable labels for rows and columns\n",
    "    od_matrix_normalized_labeled = pd.DataFrame(od_matrix_normalized.values, index=grid_ids, columns=grid_ids)\n",
    "\n",
    "    od_matrix_normalized_labeled_numpy =  od_matrix_normalized_labeled.to_numpy()\n",
    "    \n",
    "    return od_matrix_normalized_labeled_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ab309",
   "metadata": {},
   "source": [
    "### 1.2.1. Generate OD matrix for MTT, FRI, SAT & SUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ba405",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix_normalized_labeled_MTT = fn_generateODMatrix(gdf_tube_flow_MTT, london_polyframe_3857_populated)\n",
    "od_matrix_normalized_labeled_MTT\n",
    "\n",
    "od_matrix_normalized_labeled_FRI = fn_generateODMatrix(gdf_tube_flow_FRI, london_polyframe_3857_populated)\n",
    "od_matrix_normalized_labeled_FRI\n",
    "\n",
    "od_matrix_normalized_labeled_SAT = fn_generateODMatrix(gdf_tube_flow_SAT, london_polyframe_3857_populated)\n",
    "od_matrix_normalized_labeled_SAT\n",
    "\n",
    "od_matrix_normalized_labeled_SUN = fn_generateODMatrix(gdf_tube_flow_SUN, london_polyframe_3857_populated)\n",
    "od_matrix_normalized_labeled_SUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the final OD matrix for a whole week (7 days starting from Monday till Sunday)\n",
    "od_matrix_normalized_weekly = np.stack((od_matrix_normalized_labeled_MTT, od_matrix_normalized_labeled_MTT, od_matrix_normalized_labeled_MTT,\n",
    "                                        od_matrix_normalized_labeled_MTT, od_matrix_normalized_labeled_FRI, \n",
    "                                        od_matrix_normalized_labeled_SAT, od_matrix_normalized_labeled_SUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix_normalized_weekly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix_normalized_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c622adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seir_model",
   "language": "python",
   "name": "seir_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
