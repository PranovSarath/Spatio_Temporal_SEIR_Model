{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6679e5ca",
      "metadata": {
        "id": "6679e5ca"
      },
      "source": [
        "# 1. Calculate the Origin-Destination Matrix to model travel across the city grids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shapely\n",
        "!pip install geopandas\n",
        "!pip install osmnx\n",
        "!pip install contextily"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-lAoYs1WnqD",
        "outputId": "67884061-afee-41d5-accc-1792b7ab0e4c"
      },
      "id": "x-lAoYs1WnqD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5e3c8f",
      "metadata": {
        "id": "ab5e3c8f"
      },
      "outputs": [],
      "source": [
        "#Standard and specialised module imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import osmnx as ox\n",
        "import contextily as ctx\n",
        "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, shape, box\n",
        "import geopandas as gpd\n",
        "from geopy.geocoders import Nominatim, GoogleV3\n",
        "from shapely.ops import unary_union\n",
        "import networkx as nx\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Dissertation/')"
      ],
      "metadata": {
        "id": "QtQS5hDQW3mC"
      },
      "id": "QtQS5hDQW3mC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polygon_filename = 'London_grids_with_boroughs_population.shp' # @param [\"London_grids_with_population.shp\", \"London_grids_with_boroughs_population.shp\"]"
      ],
      "metadata": {
        "id": "emZEUG462aS2"
      },
      "id": "emZEUG462aS2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432263b2",
      "metadata": {
        "id": "432263b2"
      },
      "outputs": [],
      "source": [
        "gdf_london_polygons_3857_populated = gpd.read_file(polygon_filename)\n",
        "gdf_london_polygons_3857_populated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79d18ea",
      "metadata": {
        "id": "c79d18ea"
      },
      "outputs": [],
      "source": [
        "west, south, east, north = gdf_london_polygons_3857_populated.unary_union.bounds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe4e331",
      "metadata": {
        "id": "8fe4e331"
      },
      "source": [
        "## 1.1. TFL Tube Data 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73eb25b9",
      "metadata": {
        "id": "73eb25b9"
      },
      "source": [
        "### 1.1.1. Read Input Datasets (Monday to Thursday, Friday, Saturday and Sunday)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279fbe8f",
      "metadata": {
        "id": "279fbe8f"
      },
      "outputs": [],
      "source": [
        "tfl_tube_flows_data_MTT = pd.read_excel('Important Data/NBT20MTT_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
        "tfl_tube_flows_data_MTT\n",
        "\n",
        "tfl_tube_flows_data_FRI = pd.read_excel('Important Data/NBT20FRI_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
        "tfl_tube_flows_data_FRI\n",
        "\n",
        "tfl_tube_flows_data_SAT = pd.read_excel('Important Data/NBT20SAT_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
        "tfl_tube_flows_data_SAT\n",
        "\n",
        "tfl_tube_flows_data_SUN = pd.read_excel('Important Data/NBT20SUN_Outputs.xlsx', sheet_name='Link_Loads', header=2)\n",
        "tfl_tube_flows_data_SUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d89bf8",
      "metadata": {
        "id": "96d89bf8"
      },
      "outputs": [],
      "source": [
        "print(tfl_tube_flows_data_MTT.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807efebe",
      "metadata": {
        "id": "807efebe"
      },
      "outputs": [],
      "source": [
        "tfl_tube_flows_data_filtered = tfl_tube_flows_data_MTT[['Line', 'Order', 'From Station', 'To Station', 'Total']].copy()\n",
        "tfl_tube_flows_data_filtered.loc[:,'From Station'] = tfl_tube_flows_data_filtered['From Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
        "tfl_tube_flows_data_filtered.loc[:,'To Station'] = tfl_tube_flows_data_filtered['To Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
        "tfl_tube_flows_data_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778552e6",
      "metadata": {
        "id": "778552e6"
      },
      "source": [
        "### 1.1.2. Generate a dataframe containing the distinct stations in London"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e6b961",
      "metadata": {
        "id": "93e6b961"
      },
      "outputs": [],
      "source": [
        "from_station_list = tfl_tube_flows_data_filtered['From Station'].dropna().tolist()\n",
        "to_station_list = tfl_tube_flows_data_filtered['To Station'].dropna().tolist()\n",
        "\n",
        "unique_stations_list = list(set(to_station_list).union(set(from_station_list)))\n",
        "len(unique_stations_list)\n",
        "\n",
        "df_stations = pd.DataFrame({'Station Name': unique_stations_list})\n",
        "df_stations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4590ffbd",
      "metadata": {
        "id": "4590ffbd"
      },
      "source": [
        "### 1.1.3. Figure out the coordinates of the London Tube Stations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieve API Key for the Google Maps geocoding API from the YAML file."
      ],
      "metadata": {
        "id": "6EEHObQxo2YG"
      },
      "id": "6EEHObQxo2YG"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('geocoding-api-key.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "api_key = config['password']"
      ],
      "metadata": {
        "id": "9id9CONtn5uy"
      },
      "id": "9id9CONtn5uy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e5f509",
      "metadata": {
        "id": "22e5f509"
      },
      "outputs": [],
      "source": [
        "# Initialize the Nominatim geocoder\n",
        "#using GoogleMaps API\n",
        "geolocator = GoogleV3(api_key=api_key)\n",
        "geolocator.geocode(\"Waterloo London Underground\").point\n",
        "\n",
        "# Function to get the Point for each station name\n",
        "def fn_get_point_gmaps(station_name):\n",
        "    location = geolocator.geocode(station_name + \" Station, London, UK\").point\n",
        "    if location:\n",
        "        return Point(location.longitude, location.latitude)  # Note: Longitude comes first, then Latitude\n",
        "    else:\n",
        "        location = geolocator.geocode(station_name + \" , London, UK\").point\n",
        "        if location:\n",
        "            return Point(location.longitude, location.latitude)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "# Apply the function to the 'StationName' column and create a new 'Point' column\n",
        "df_stations['Point'] = df_stations['Station Name'].apply(fn_get_point_gmaps)\n",
        "df_stations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c058d7",
      "metadata": {
        "id": "07c058d7"
      },
      "outputs": [],
      "source": [
        "df_stations = df_stations.rename(columns={'Point':'geometry'})\n",
        "gdf_stations = gpd.GeoDataFrame(df_stations, crs='epsg:4326')\n",
        "gdf_stations.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ce3779",
      "metadata": {
        "id": "75ce3779"
      },
      "outputs": [],
      "source": [
        "gdf_stations = gdf_stations.to_crs('3857')\n",
        "gdf_stations.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7740f146",
      "metadata": {
        "id": "7740f146"
      },
      "outputs": [],
      "source": [
        "#add the rest of the map in the background\n",
        "fig, ax = plt.subplots(figsize=(30, 30))\n",
        "gdf_stations.plot(ax=ax ,figsize=(30,30), alpha=0.5, edgecolor='r', linewidth=10, cmap='magma') #column = 'geometry'\n",
        "gdf_london_polygons_3857_populated.plot(figsize=(30, 30), ax=ax ,alpha=0.5, edgecolor='k',linewidth=3)\n",
        "for idx, row in gdf_london_polygons_3857_populated.iterrows():\n",
        "    if 'NAME' in gdf_london_polygons_3857_populated.columns:\n",
        "      label = row['NAME']  # Replace 'grid_index' with the desired column containing labels or information\n",
        "    else:\n",
        "      label = row[\"grid_index\"]\n",
        "    centroid_coords = row['geometry'].centroid.coords[0]\n",
        "    ax.annotate(text=label, xy=centroid_coords, horizontalalignment='center', size=10)\n",
        "\n",
        "ctx.add_basemap(ax, zoom=13)\n",
        "#ax.set_xlim(west, east)\n",
        "#ax.set_ylim(south, north)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67a2a7c6",
      "metadata": {
        "id": "67a2a7c6"
      },
      "outputs": [],
      "source": [
        "def fn_buildGriddedTubeDataset(gdf_tube_dataset_input, gdf_stations_london, gdf_population_data):\n",
        "\n",
        "    gdf_tube_dataset_filtered_input = gdf_tube_dataset_input[['Line', 'Order', 'From Station', 'To Station', 'Total']].copy()\n",
        "    gdf_tube_dataset_filtered_input.loc[:,'From Station'] = gdf_tube_dataset_filtered_input['From Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
        "    gdf_tube_dataset_filtered_input.loc[:,'To Station'] = gdf_tube_dataset_filtered_input['To Station'].str.replace(r'\\bLU\\b', 'London Underground', regex=True)\n",
        "    print(gdf_tube_dataset_filtered_input)\n",
        "\n",
        "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input.merge(gdf_stations_london, left_on='From Station', right_on='Station Name', how='inner')\n",
        "    gdf_tube_dataset_filtered_input_coords['From Station Coords'] = gdf_tube_dataset_filtered_input_coords['geometry']\n",
        "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.drop(['geometry', 'Station Name'], axis=1)\n",
        "\n",
        "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.merge(gdf_stations_london, left_on='To Station', right_on='Station Name', how='inner')\n",
        "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.rename(columns={'geometry': 'To Station Coords'})\n",
        "    gdf_tube_dataset_filtered_input_coords = gdf_tube_dataset_filtered_input_coords.drop(['Station Name'], axis=1)\n",
        "    print(gdf_tube_dataset_filtered_input_coords)\n",
        "\n",
        "    gdf_tube_dataset_filtered_input_coords_from = gdf_tube_dataset_filtered_input_coords.copy()\n",
        "    gdf_tube_dataset_filtered_input_coords_from['geometry'] = gdf_tube_dataset_filtered_input_coords_from['From Station Coords']\n",
        "    gdf_tube_dataset_filtered_input_coords_from = gpd.GeoDataFrame(gdf_tube_dataset_filtered_input_coords_from, crs='3857')\n",
        "    gdf_tube_dataset_filtered_input_coords_from\n",
        "\n",
        "\n",
        "    start_join = gpd.sjoin(gdf_tube_dataset_filtered_input_coords_from.to_crs('3857'), gdf_population_data[['geometry', 'grid_index']].to_crs('3857'), how='left', predicate='within')\n",
        "    start_join['From Grid ID'] = start_join['grid_index']\n",
        "    start_join = start_join.drop(['index_right', 'grid_index'], axis=1)\n",
        "\n",
        "    start_join['geometry'] = start_join['To Station Coords']\n",
        "    end_join = gpd.sjoin(start_join.to_crs('3857'), gdf_population_data[['geometry', 'grid_index']].to_crs('3857'), how='left', predicate='within')\n",
        "    end_join['To Grid ID'] = end_join['grid_index']\n",
        "    end_join = end_join.drop(['index_right','grid_index'], axis=1)\n",
        "    print(end_join)\n",
        "\n",
        "    #Filter out stations that lie outside the London city limits\n",
        "    end_join_filtered = end_join[~end_join['To Grid ID'].isnull() & ~end_join['From Grid ID'].isnull()]\n",
        "    end_join_filtered\n",
        "\n",
        "    return end_join_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b495fab",
      "metadata": {
        "id": "2b495fab"
      },
      "source": [
        "### 1.1.3. Calculate the Flow Data for MTT, FRI, SAT and SUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01361db0",
      "metadata": {
        "id": "01361db0"
      },
      "outputs": [],
      "source": [
        "gdf_tube_flow_MTT = fn_buildGriddedTubeDataset(tfl_tube_flows_data_MTT, gdf_stations, gdf_london_polygons_3857_populated)\n",
        "gdf_tube_flow_MTT\n",
        "\n",
        "gdf_tube_flow_FRI = fn_buildGriddedTubeDataset(tfl_tube_flows_data_FRI, gdf_stations, gdf_london_polygons_3857_populated)\n",
        "gdf_tube_flow_FRI\n",
        "\n",
        "gdf_tube_flow_SAT = fn_buildGriddedTubeDataset(tfl_tube_flows_data_SAT, gdf_stations, gdf_london_polygons_3857_populated)\n",
        "gdf_tube_flow_SAT\n",
        "\n",
        "gdf_tube_flow_SUN = fn_buildGriddedTubeDataset(tfl_tube_flows_data_SUN, gdf_stations, gdf_london_polygons_3857_populated)\n",
        "gdf_tube_flow_SUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53333d7d",
      "metadata": {
        "id": "53333d7d"
      },
      "outputs": [],
      "source": [
        "#add the rest of the map in the background\n",
        "fig, ax = plt.subplots(figsize=(30, 30))\n",
        "gdf_tube_flow_MTT.plot(figsize=(30, 30), ax=ax, alpha=0.5, edgecolor='r', linewidth=30) #, column='geometry'\n",
        "gdf_london_polygons_3857_populated.plot(figsize=(30, 30),alpha=0.5, ax=ax, edgecolor='k',linewidth=3) #'geometry'\n",
        "\n",
        "for idx, row in gdf_london_polygons_3857_populated.iterrows():\n",
        "    if 'NAME' in gdf_london_polygons_3857_populated.columns:\n",
        "      label = row['NAME']  # Replace 'grid_index' with the desired column containing labels or information\n",
        "    else:\n",
        "      label = row[\"grid_index\"]\n",
        "    centroid_coords = row['geometry'].centroid.coords[0]\n",
        "    ax.annotate(text=label, xy=centroid_coords, horizontalalignment='center', size=30)\n",
        "\n",
        "ctx.add_basemap(ax, zoom=13)\n",
        "ax.set_xlim(west, east)\n",
        "ax.set_ylim(south, north)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c987ee60",
      "metadata": {
        "id": "c987ee60"
      },
      "source": [
        "## 1.2. Build the Origin-Destination Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc1240e",
      "metadata": {
        "id": "abc1240e"
      },
      "outputs": [],
      "source": [
        "def fn_generateODMatrix(gdf_flow_dataset, gdf_population_data):\n",
        "    # Get the unique Grid IDs\n",
        "    grid_ids = gdf_population_data['grid_index'].unique()\n",
        "\n",
        "    # Create a weighted graph using NetworkX\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add edges with total people as edge weights\n",
        "    for index, row in gdf_flow_dataset.iterrows():\n",
        "        from_grid_id = row['From Grid ID']\n",
        "        to_grid_id = row['To Grid ID']\n",
        "        total_people = row['Total']\n",
        "\n",
        "        if G.has_edge(from_grid_id, to_grid_id):\n",
        "            G[from_grid_id][to_grid_id]['weight'] += total_people\n",
        "        else:\n",
        "            G.add_edge(from_grid_id, to_grid_id, weight=total_people)\n",
        "\n",
        "    # Use Floyd-Warshall algorithm to find shortest paths and total flow between all pairs of grids\n",
        "    all_pairs_shortest_paths = dict(nx.floyd_warshall(G, weight='weight'))\n",
        "\n",
        "    # Create a square matrix to store the OD flow\n",
        "    od_matrix = pd.DataFrame(np.zeros((len(grid_ids), len(grid_ids))), index=grid_ids, columns=grid_ids, dtype=float)\n",
        "\n",
        "    # Populate the OD matrix with total flow between all pairs of grids\n",
        "    for from_grid_id, to_grid_data in all_pairs_shortest_paths.items():\n",
        "        for to_grid_id, total_flow in to_grid_data.items():\n",
        "            od_matrix.at[from_grid_id, to_grid_id] = total_flow\n",
        "\n",
        "    # Normalize the OD matrix to values between 0 and 1\n",
        "    #od_matrix_normalized = (od_matrix - od_matrix.min().min()) / (od_matrix.max().max() - od_matrix.min().min())\n",
        "\n",
        "    # Normalize the OD matrix to values between 0 and 1\n",
        "    row_sums = od_matrix.sum(axis=1)\n",
        "    od_matrix_normalized = od_matrix.div(row_sums, axis=0)\n",
        "    #od_matrix_normalized = od_matrix.fillna(0.0)\n",
        "    #od_matrix_normalized = round(od_matrix_normalized,5)\n",
        "\n",
        "    for index, row in od_matrix_normalized.iterrows():\n",
        "        if not np.isclose(row.sum(), 1.0):  # Handle potential floating-point inaccuracies\n",
        "            od_matrix_normalized.loc[index] = row / row.sum()\n",
        "\n",
        "    # Handle division by zero and set NaN values to 0\n",
        "    od_matrix_normalized = od_matrix_normalized.fillna(0.0)\n",
        "\n",
        "    # Optionally, you can add human-readable labels for rows and columns\n",
        "    od_matrix_normalized_labeled = pd.DataFrame(od_matrix_normalized.values, index=grid_ids, columns=grid_ids)\n",
        "\n",
        "    od_matrix_normalized_labeled_numpy =  od_matrix_normalized_labeled.to_numpy()\n",
        "\n",
        "    return od_matrix_normalized_labeled_numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26ab309",
      "metadata": {
        "id": "b26ab309"
      },
      "source": [
        "### 1.2.1. Generate OD matrix for MTT, FRI, SAT & SUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9ba405",
      "metadata": {
        "id": "3a9ba405"
      },
      "outputs": [],
      "source": [
        "od_matrix_normalized_labeled_MTT = fn_generateODMatrix(gdf_tube_flow_MTT, gdf_london_polygons_3857_populated)\n",
        "od_matrix_normalized_labeled_MTT\n",
        "\n",
        "od_matrix_normalized_labeled_FRI = fn_generateODMatrix(gdf_tube_flow_FRI, gdf_london_polygons_3857_populated)\n",
        "od_matrix_normalized_labeled_FRI\n",
        "\n",
        "od_matrix_normalized_labeled_SAT = fn_generateODMatrix(gdf_tube_flow_SAT, gdf_london_polygons_3857_populated)\n",
        "od_matrix_normalized_labeled_SAT\n",
        "\n",
        "od_matrix_normalized_labeled_SUN = fn_generateODMatrix(gdf_tube_flow_SUN, gdf_london_polygons_3857_populated)\n",
        "od_matrix_normalized_labeled_SUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f58d86da",
      "metadata": {
        "id": "f58d86da"
      },
      "outputs": [],
      "source": [
        "#Generate the final OD matrix for a whole week (7 days starting from Monday till Sunday)\n",
        "od_matrix_normalized_weekly = np.stack((od_matrix_normalized_labeled_MTT, od_matrix_normalized_labeled_MTT, od_matrix_normalized_labeled_MTT,\n",
        "                                        od_matrix_normalized_labeled_MTT, od_matrix_normalized_labeled_FRI,\n",
        "                                        od_matrix_normalized_labeled_SAT, od_matrix_normalized_labeled_SUN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "699d48a4",
      "metadata": {
        "id": "699d48a4"
      },
      "outputs": [],
      "source": [
        "od_matrix_normalized_weekly.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4775f0be",
      "metadata": {
        "id": "4775f0be"
      },
      "outputs": [],
      "source": [
        "od_matrix_normalized_weekly[0].sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b9c48dd",
      "metadata": {
        "id": "0b9c48dd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "diss_seir",
      "language": "python",
      "name": "diss_seir"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}